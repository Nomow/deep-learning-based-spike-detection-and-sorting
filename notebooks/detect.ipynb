{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ryGVws49WiGo"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from os.path import expanduser\n",
    "from os import path\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ePu-e7SjWdt_"
   },
   "outputs": [],
   "source": [
    "root_folder = os.path.dirname(os.getcwd())\n",
    "path_to_recording= path.join(root_folder,'data/recording_datasets/datasets_2.npy');\n",
    "path_to_model = path.join(root_folder, 'models/resnet18_num_classes_2_epoch_0.pt')\n",
    "path_to_results = path.join(root_folder, 'data/results/datasets_1_results.npy')\n",
    "\n",
    "sys.path.append(root_folder)\n",
    "from custom_resnet import CustomResnet as cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yV5TaTbXZ0EZ"
   },
   "outputs": [],
   "source": [
    "waveform_length = 72;\n",
    "step_size = int(np.round(waveform_length * 0.1))\n",
    "batch_size = 60000;\n",
    "num_classes = 2;\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = cnn.resnet18(num_classes=num_classes);\n",
    "checkpoint = torch.load(path_to_model)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.to(device);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M1ISyqPybIfA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72000000\n",
      "tensor([-0.4852, -0.0765,  0.0115, -0.3168, -0.8177, -1.1595, -1.3421, -1.4938,\n",
      "        -1.5787, -1.5511, -1.4830, -1.4844, -1.5745, -1.6838, -1.6920, -1.5752,\n",
      "        -1.4379, -1.3655, -1.3350, -1.2545, -1.0723, -0.7421, -0.2437,  0.3325,\n",
      "         0.7915,  0.9613,  0.8495,  0.6891,  0.6677,  0.7274,  0.7781,  0.8906,\n",
      "         1.1738,  1.5295,  1.7142,  1.7459,  1.9466,  2.3850,  2.7226,  2.7006,\n",
      "         2.3137,  1.6934,  1.0278,  0.5063,  0.1528, -0.0873, -0.2789, -0.4114,\n",
      "        -0.4238, -0.3308, -0.1393,  0.1240,  0.2714,  0.0547, -0.3991, -0.7987,\n",
      "        -0.9988, -0.9398, -0.5659,  0.1558,  0.8844,  1.1747,  1.0718,  0.9475,\n",
      "         1.0456,  1.2560,  1.3518,  1.2474,  1.0342,  0.7762,  0.4605,  0.1095,\n",
      "        -0.1335, -0.2250, -0.2098, -0.1273, -0.0247,  0.0788,  0.1373,  0.0759,\n",
      "        -0.0732, -0.0366,  0.2924,  0.6132,  0.6220,  0.3356, -0.0087, -0.2095,\n",
      "        -0.2549, -0.2624, -0.3526, -0.5380, -0.6964, -0.7022, -0.5567, -0.4517,\n",
      "        -0.5400, -0.7467, -0.9199, -0.9799])\n",
      "tensor(-0.0011)\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([cnn.MovingWeightedMeanAndStdNormalization(1000)])\n",
    "recording = cnn.Recording(path_to_recording, transform = transform);\n",
    "recording = cnn.AddPaddingToRecording(recording, step_size, waveform_length)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "k8V4ZFbteosZ",
    "outputId": "ad523e6d-963f-4a59-9d77-b43364a5c6d9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6N_R4qANQSVh"
   },
   "outputs": [],
   "source": [
    "waveform_indices = cnn.GetWaveformIndices(recording, step_size, waveform_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KQ1z4-C0HHH2"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([cnn.ExtractWaveforms(waveform_indices, waveform_length)])\n",
    "waveforms = transform(recording.data);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "wPe3Lpbny25l",
    "outputId": "05bf582f-4262-4915-ebd9-f6d4c251d9bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "normalized_waveforms = waveforms;\n",
    "dataset_to_infer = cnn.InferenceDataset(normalized_waveforms.to(device));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2958
    },
    "colab_type": "code",
    "id": "AX2Tdh3YIEQ_",
    "outputId": "b9f67fd2-6dd8-4f47-b0d0-60381b94fde8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n",
      "done:  0  batch\n",
      "done:  1  batch\n",
      "done:  2  batch\n",
      "done:  3  batch\n",
      "done:  4  batch\n",
      "done:  5  batch\n",
      "done:  6  batch\n",
      "done:  7  batch\n",
      "done:  8  batch\n",
      "done:  9  batch\n",
      "done:  10  batch\n",
      "done:  11  batch\n",
      "done:  12  batch\n",
      "done:  13  batch\n",
      "done:  14  batch\n",
      "done:  15  batch\n",
      "done:  16  batch\n",
      "done:  17  batch\n",
      "done:  18  batch\n",
      "done:  19  batch\n",
      "done:  20  batch\n",
      "done:  21  batch\n",
      "done:  22  batch\n",
      "done:  23  batch\n",
      "done:  24  batch\n",
      "done:  25  batch\n",
      "done:  26  batch\n",
      "done:  27  batch\n",
      "done:  28  batch\n",
      "done:  29  batch\n",
      "done:  30  batch\n",
      "done:  31  batch\n",
      "done:  32  batch\n",
      "done:  33  batch\n",
      "done:  34  batch\n",
      "done:  35  batch\n",
      "done:  36  batch\n",
      "done:  37  batch\n",
      "done:  38  batch\n",
      "done:  39  batch\n",
      "done:  40  batch\n",
      "done:  41  batch\n",
      "done:  42  batch\n",
      "done:  43  batch\n",
      "done:  44  batch\n",
      "done:  45  batch\n",
      "done:  46  batch\n",
      "done:  47  batch\n",
      "done:  48  batch\n",
      "done:  49  batch\n",
      "done:  50  batch\n",
      "done:  51  batch\n",
      "done:  52  batch\n",
      "done:  53  batch\n",
      "done:  54  batch\n",
      "done:  55  batch\n",
      "done:  56  batch\n",
      "done:  57  batch\n",
      "done:  58  batch\n",
      "done:  59  batch\n",
      "done:  60  batch\n",
      "done:  61  batch\n",
      "done:  62  batch\n",
      "done:  63  batch\n",
      "done:  64  batch\n",
      "done:  65  batch\n",
      "done:  66  batch\n",
      "done:  67  batch\n",
      "done:  68  batch\n",
      "done:  69  batch\n",
      "done:  70  batch\n",
      "done:  71  batch\n",
      "done:  72  batch\n",
      "done:  73  batch\n",
      "done:  74  batch\n",
      "done:  75  batch\n",
      "done:  76  batch\n",
      "done:  77  batch\n",
      "done:  78  batch\n",
      "done:  79  batch\n",
      "done:  80  batch\n",
      "done:  81  batch\n",
      "done:  82  batch\n",
      "done:  83  batch\n",
      "done:  84  batch\n",
      "done:  85  batch\n",
      "done:  86  batch\n",
      "done:  87  batch\n",
      "done:  88  batch\n",
      "done:  89  batch\n",
      "done:  90  batch\n",
      "done:  91  batch\n",
      "done:  92  batch\n",
      "done:  93  batch\n",
      "done:  94  batch\n",
      "done:  95  batch\n",
      "done:  96  batch\n",
      "done:  97  batch\n",
      "done:  98  batch\n",
      "done:  99  batch\n",
      "done:  100  batch\n",
      "done:  101  batch\n",
      "done:  102  batch\n",
      "done:  103  batch\n",
      "done:  104  batch\n",
      "done:  105  batch\n",
      "done:  106  batch\n",
      "done:  107  batch\n",
      "done:  108  batch\n",
      "done:  109  batch\n",
      "done:  110  batch\n",
      "done:  111  batch\n",
      "done:  112  batch\n",
      "done:  113  batch\n",
      "done:  114  batch\n",
      "done:  115  batch\n",
      "done:  116  batch\n",
      "done:  117  batch\n",
      "done:  118  batch\n",
      "done:  119  batch\n",
      "done:  120  batch\n",
      "done:  121  batch\n",
      "done:  122  batch\n",
      "done:  123  batch\n",
      "done:  124  batch\n",
      "done:  125  batch\n",
      "done:  126  batch\n",
      "done:  127  batch\n",
      "done:  128  batch\n",
      "done:  129  batch\n",
      "done:  130  batch\n",
      "done:  131  batch\n",
      "done:  132  batch\n",
      "done:  133  batch\n",
      "done:  134  batch\n",
      "done:  135  batch\n",
      "done:  136  batch\n",
      "done:  137  batch\n",
      "done:  138  batch\n",
      "done:  139  batch\n",
      "done:  140  batch\n",
      "done:  141  batch\n",
      "done:  142  batch\n",
      "done:  143  batch\n",
      "done:  144  batch\n",
      "done:  145  batch\n",
      "done:  146  batch\n",
      "done:  147  batch\n",
      "done:  148  batch\n",
      "done:  149  batch\n",
      "done:  150  batch\n",
      "done:  151  batch\n",
      "done:  152  batch\n",
      "done:  153  batch\n",
      "done:  154  batch\n",
      "done:  155  batch\n",
      "done:  156  batch\n",
      "done:  157  batch\n",
      "done:  158  batch\n",
      "done:  159  batch\n",
      "done:  160  batch\n",
      "done:  161  batch\n",
      "done:  162  batch\n",
      "done:  163  batch\n",
      "done:  164  batch\n",
      "done:  165  batch\n",
      "done:  166  batch\n",
      "done:  167  batch\n",
      "done:  168  batch\n",
      "done:  169  batch\n",
      "done:  170  batch\n",
      "done:  171  batch\n"
     ]
    }
   ],
   "source": [
    "%pdb off\n",
    "data_loader = torch.utils.data.DataLoader(dataset_to_infer, batch_size=batch_size, shuffle=False, num_workers=0);\n",
    "result = cnn.Inference(model, data_loader, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "epc6ksTR2Q9x"
   },
   "outputs": [],
   "source": [
    "soft_max = nn.Softmax(1)\n",
    "probability = soft_max(result)\n",
    "argmax = torch.argmax(probability, 1);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ajhuF_PAPttn"
   },
   "outputs": [],
   "source": [
    "def predictionByTreshold(result, treshold):\n",
    "  soft_max = nn.Softmax(1)\n",
    "  probability = soft_max(result)\n",
    "  prediction = torch.argmax(probability, 1);\n",
    "  for i  in range(prediction.nelement()):\n",
    "    if prediction[i] > 0:\n",
    "      score = probability[i, prediction[i]];\n",
    "      if(score < treshold):\n",
    "        prediction[i] = 0;\n",
    "  return prediction;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tF_PTUoEQdAz"
   },
   "outputs": [],
   "source": [
    "treshold = 0.85;\n",
    "predictions = predictionByTreshold(result, treshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "nUoZ1hFPQqmC",
    "outputId": "5b95a1f2-6ee4-44fb-9bac-caf50a07332d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(724283,)\n",
      "(9561421,)\n"
     ]
    }
   ],
   "source": [
    "print(np.where(predictions == 1)[0].shape)\n",
    "print(np.where(predictions == 0)[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "O93nvnKSMrk2",
    "outputId": "aba71866-5fc5-46ef-9272-5b926eac427a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1083899,)\n",
      "(9201805,)\n"
     ]
    }
   ],
   "source": [
    "print(np.where(argmax == 1)[0].shape)\n",
    "print(np.where(argmax == 0)[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NpJiOLTBI45R"
   },
   "outputs": [],
   "source": [
    "shift_check = 1\n",
    "classes = [1]\n",
    "extracted_sequences = []\n",
    "temp = [];\n",
    "for i in range(0, predictions.nelement()):\n",
    "  append_sequence = True;\n",
    "  current_class = None\n",
    "  for j in range(0, len(classes)):\n",
    "    class_id = classes[j];\n",
    "    if(predictions[i] == class_id):\n",
    "      temp.append(i);\n",
    "      if(predictions.nelement() - shift_check  > i):\n",
    "        for k in range(1, shift_check + 1):\n",
    "          if(predictions[i+k] == class_id):\n",
    "            append_sequence = False;\n",
    "  if(append_sequence and len(temp) != 0):\n",
    "    extracted_sequences.append(temp)\n",
    "    temp = [];\n",
    "          \n",
    "\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MQfzOZAOToi1",
    "outputId": "18d70ae5-dec9-497b-e878-f80db7010c79"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96969"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(extracted_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C7CS5MNhKHHQ"
   },
   "outputs": [],
   "source": [
    "#for seq in extracted_sequences:\n",
    "#  print(len(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ai8_5V1Xp2Vp"
   },
   "outputs": [],
   "source": [
    "predicted_index_from_to = np.zeros((len(extracted_sequences), 2));\n",
    "for i, spike in enumerate(extracted_sequences):\n",
    "  predicted_index_from_to[i, 0] = waveform_indices[0, spike[0]] - waveform_length // 2;\n",
    "  predicted_index_from_to[i, 1] = waveform_indices[0, spike[-1]] + waveform_length // 2;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "93_pM9LIKBwO"
   },
   "outputs": [],
   "source": [
    "predicted_index_from_to = predicted_index_from_to.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CI7B8PFq-sS-"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "max_index = np.zeros((len(predicted_index_from_to)))\n",
    "for i in range(0, len(predicted_index_from_to)):\n",
    "  wf = abs(recording[0, predicted_index_from_to[i, 0]:predicted_index_from_to[i, 1] ])\n",
    "  max_index[i] =  predicted_index_from_to[i, 0] + np.argmax(wf);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aBKBpQqUD6XT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qj5cKZqyALve",
    "outputId": "3f722d04-6b3b-4492-f7bc-580f98379c34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58481\n"
     ]
    }
   ],
   "source": [
    "path_to_ground_truth_data = path.join(root_folder,'data/recording_datasets/ground_truth_data_multiunit_2.npy');\n",
    "ground_truth = np.load(path_to_ground_truth_data);\n",
    "neuron_indexes = ground_truth[1, :];\n",
    "spike_positions = ground_truth[0, :];\n",
    "spike_positions = spike_positions.astype(int)\n",
    "\n",
    "spike_positions.shape\n",
    "total = spike_positions.size\n",
    "print(total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S5OUm7EdXdjC"
   },
   "outputs": [],
   "source": [
    "max_index_unique = np.unique(max_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Tcwi1Oody_Jt",
    "outputId": "4337b448-d3ab-4b80-ec57-f38138584405"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    1516,     1763,     1893, ..., 71997977, 71999418, 71999801])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_index_unique.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "S7c4SnT4wtEl",
    "outputId": "3b419545-e7c3-49aa-8f58-484fb3186860"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90288,)\n",
      "(96969,)\n"
     ]
    }
   ],
   "source": [
    "print(max_index_unique.shape)\n",
    "print(max_index.shape)\n",
    "np.save(path_to_results, max_index_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s_A2PqtnAr4V"
   },
   "outputs": [],
   "source": [
    "is_found = np.zeros(max_index_unique.size)\n",
    "for i in range(0, max_index_unique.size):\n",
    "  found = np.where(max_index_unique[i] == spike_positions)\n",
    "  if(len(found[0]) == 0):\n",
    "    is_found[i] = 0\n",
    "  else:\n",
    "    is_found[i] = 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "IQxfsJr5CML-",
    "outputId": "851b20ac-626b-4d0b-db2b-b4487356f523"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56610\n",
      "33678\n",
      "-31807\n"
     ]
    }
   ],
   "source": [
    "tp = np.where(is_found == 1)[0].size\n",
    "print(tp)\n",
    "fp = np.where(is_found == 0)[0].size\n",
    "print(fp)\n",
    "fn = total - tp - fp\n",
    "print(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "X9tjePkXoZNt",
    "outputId": "c83a526d-bc2d-4c33-c002-f6d188be5f37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.626993620414673\n",
      "2.2823851953392733\n",
      "0.9837432987809644\n"
     ]
    }
   ],
   "source": [
    "precision = tp / (tp + fp)\n",
    "print(precision)\n",
    "recall = tp / (tp + fn)\n",
    "print(recall)\n",
    "f1 = 2 * ((precision * recall) / (precision + recall))\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "yFMkTdMfoG_p",
    "outputId": "0939ea82-fc77-47f3-9f22-7dd25a0a42c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56610"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dkvx5BvOraR5",
    "outputId": "90d178d4-3df3-4052-83ef-073bbabb1b0b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.968006703031754"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-91B5hSunjzw"
   },
   "outputs": [],
   "source": [
    "# tp is spike\n",
    "# fp is noise but predicted as spike\n",
    "# tn is noise\n",
    "# fn is spike but predicted as noise"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "detect.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

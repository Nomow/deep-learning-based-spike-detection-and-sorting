{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from os.path import expanduser\n",
    "from os import path\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder = os.path.dirname(os.getcwd())\n",
    "path_to_ground_truth_data = path.join(root_folder,'data/synthesized/gt_85.npy');\n",
    "path_to_recording= path.join(root_folder,'data/synthesized/data_85.npy');\n",
    "\n",
    "sys.path.append(root_folder)\n",
    "from custom_resnet import CustomResnet as cnn\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "waveform_length = 72;\n",
    "step_size = int(np.round(waveform_length * 0.1))\n",
    "batch_size = 15000;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads spike detection model\n",
    "num_classes_detect = 2;\n",
    "path_to_model_detect = path.join(root_folder, 'models/detect/resnet18_num_classes_2_epoch_24.pt')\n",
    "model_detect = cnn.resnet18(num_classes=num_classes_detect);\n",
    "checkpoint = torch.load(path_to_model_detect)\n",
    "model_detect.load_state_dict(checkpoint['model_state_dict'])\n",
    "model_detect.to(device);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads re id model\n",
    "num_classes_re_id = 499;\n",
    "path_to_model_re_id = path.join(root_folder, 'models/re_id/resnet18_num_classes_499_epoch_74.pt')\n",
    "model_re_id = cnn.ft_net(class_num = num_classes_re_id);\n",
    "checkpoint = torch.load(path_to_model_re_id)\n",
    "model_re_id.load_state_dict(checkpoint['model_state_dict'])\n",
    "model_re_id.to(device);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.98707844 -0.98707844] [ 1.         -0.97415687]\n"
     ]
    }
   ],
   "source": [
    "# transforms data for inference\n",
    "transform = transforms.Compose([cnn.FilterSignalUsingButtersWorth('high', 24000, np.array([100], dtype=int), 1), cnn.OptimizedZScoreNormalizaton()])\n",
    "recording = cnn.Recording(path_to_recording, transform = transform);\n",
    "recording = cnn.AddPaddingToRecording(recording, step_size, waveform_length)\n",
    "# gets waveform data for each window\n",
    "waveform_indices = cnn.GetWaveformIndices(recording, step_size, waveform_length)\n",
    "transform = transforms.Compose([cnn.ExtractWaveforms(waveform_indices, waveform_length)])\n",
    "waveforms = transform(recording.data);\n",
    "normalized_waveforms = waveforms;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.FloatTensor\n",
      "done:  0  batch\n",
      "done:  1  batch\n",
      "done:  2  batch\n",
      "done:  3  batch\n",
      "done:  4  batch\n",
      "done:  5  batch\n",
      "done:  6  batch\n",
      "done:  7  batch\n",
      "done:  8  batch\n",
      "done:  9  batch\n",
      "done:  10  batch\n",
      "done:  11  batch\n",
      "done:  12  batch\n",
      "done:  13  batch\n",
      "done:  14  batch\n",
      "done:  15  batch\n",
      "done:  16  batch\n",
      "done:  17  batch\n",
      "done:  18  batch\n",
      "done:  19  batch\n",
      "done:  20  batch\n",
      "done:  21  batch\n",
      "done:  22  batch\n",
      "done:  23  batch\n",
      "done:  24  batch\n",
      "done:  25  batch\n",
      "done:  26  batch\n",
      "done:  27  batch\n",
      "done:  28  batch\n",
      "done:  29  batch\n",
      "done:  30  batch\n",
      "done:  31  batch\n",
      "done:  32  batch\n",
      "done:  33  batch\n",
      "done:  34  batch\n",
      "done:  35  batch\n",
      "done:  36  batch\n",
      "done:  37  batch\n",
      "done:  38  batch\n",
      "done:  39  batch\n",
      "done:  40  batch\n",
      "done:  41  batch\n",
      "done:  42  batch\n",
      "done:  43  batch\n",
      "done:  44  batch\n",
      "done:  45  batch\n",
      "done:  46  batch\n",
      "done:  47  batch\n",
      "done:  48  batch\n",
      "done:  49  batch\n",
      "done:  50  batch\n",
      "done:  51  batch\n",
      "done:  52  batch\n",
      "done:  53  batch\n",
      "done:  54  batch\n",
      "done:  55  batch\n",
      "done:  56  batch\n",
      "done:  57  batch\n",
      "done:  58  batch\n",
      "done:  59  batch\n",
      "done:  60  batch\n",
      "done:  61  batch\n",
      "done:  62  batch\n",
      "done:  63  batch\n",
      "done:  64  batch\n",
      "done:  65  batch\n",
      "done:  66  batch\n",
      "done:  67  batch\n",
      "done:  68  batch\n",
      "done:  69  batch\n",
      "done:  70  batch\n",
      "done:  71  batch\n",
      "done:  72  batch\n",
      "done:  73  batch\n",
      "done:  74  batch\n",
      "done:  75  batch\n",
      "done:  76  batch\n",
      "done:  77  batch\n",
      "done:  78  batch\n",
      "done:  79  batch\n",
      "done:  80  batch\n",
      "done:  81  batch\n",
      "done:  82  batch\n",
      "done:  83  batch\n",
      "done:  84  batch\n",
      "done:  85  batch\n",
      "done:  86  batch\n",
      "done:  87  batch\n",
      "done:  88  batch\n",
      "done:  89  batch\n",
      "done:  90  batch\n",
      "done:  91  batch\n",
      "done:  92  batch\n",
      "done:  93  batch\n",
      "done:  94  batch\n",
      "done:  95  batch\n",
      "done:  96  batch\n",
      "done:  97  batch\n",
      "done:  98  batch\n",
      "done:  99  batch\n",
      "done:  100  batch\n",
      "done:  101  batch\n",
      "done:  102  batch\n",
      "done:  103  batch\n",
      "done:  104  batch\n",
      "done:  105  batch\n",
      "done:  106  batch\n",
      "done:  107  batch\n",
      "done:  108  batch\n",
      "done:  109  batch\n",
      "done:  110  batch\n",
      "done:  111  batch\n",
      "done:  112  batch\n",
      "done:  113  batch\n",
      "done:  114  batch\n",
      "done:  115  batch\n",
      "done:  116  batch\n",
      "done:  117  batch\n",
      "done:  118  batch\n",
      "done:  119  batch\n",
      "done:  120  batch\n",
      "done:  121  batch\n",
      "done:  122  batch\n",
      "done:  123  batch\n",
      "done:  124  batch\n",
      "done:  125  batch\n",
      "done:  126  batch\n",
      "done:  127  batch\n",
      "done:  128  batch\n",
      "done:  129  batch\n",
      "done:  130  batch\n",
      "done:  131  batch\n",
      "done:  132  batch\n",
      "done:  133  batch\n",
      "done:  134  batch\n",
      "done:  135  batch\n",
      "done:  136  batch\n",
      "done:  137  batch\n"
     ]
    }
   ],
   "source": [
    "### spike detection pipeline\n",
    "# loads data for inference\n",
    "dataset_to_infer_detect = cnn.InferenceDataset(normalized_waveforms.to(device));\n",
    "data_loader_detect = torch.utils.data.DataLoader(dataset_to_infer_detect, batch_size=batch_size, shuffle=False, num_workers=0);\n",
    "\n",
    "#inference for detection \n",
    "result_detect = cnn.Inference(model_detect, data_loader_detect, num_classes_detect)\n",
    "treshold = 0.9;\n",
    "predictions = cnn.PredictionByTreshold(result_detect, treshold)\n",
    "max_amplitude_index = cnn.GetNonOverlappingSpikesMaxAmplitude(recording, predictions, waveform_length, waveforms, waveform_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dataset_to_infer_detect, data_loader_detect\n",
    "torch.cuda.empty_cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_amplitude_index = torch.unsqueeze(torch.tensor(max_amplitude_index), 0);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 15154])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_amplitude_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.FloatTensor\n",
      "torch.cuda.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "# spike classficiation pipeline\n",
    "transform = transforms.Compose([cnn.ExtractWaveforms(max_amplitude_index, waveform_length)])\n",
    "waveforms_re_id = transform(recording.data);\n",
    "#vertical flip\n",
    "waveforms_re_id_flipped = waveforms_re_id * -1;\n",
    "# data loading for inference\n",
    "dataset_to_re_id = cnn.InferenceDataset(waveforms_re_id.to(device));\n",
    "data_loader_re_id = torch.utils.data.DataLoader(dataset_to_re_id, batch_size=batch_size, shuffle=False, num_workers=0);\n",
    "dataset_to_re_id_flipped = cnn.InferenceDataset(waveforms_re_id_flipped.to(device));\n",
    "data_loader_re_id_flipped = torch.utils.data.DataLoader(dataset_to_re_id_flipped, batch_size=batch_size, shuffle=False, num_workers=0);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done:  0  batch\n",
      "done:  1  batch\n",
      "done:  0  batch\n",
      "done:  1  batch\n"
     ]
    }
   ],
   "source": [
    "# exracts features\n",
    "feature_map_dims = 128\n",
    "features = torch.FloatTensor(0 , 128).zero_();\n",
    "model_re_id.model.fc.classifier = nn.Sequential()\n",
    "result_re_id = cnn.Inference(model_re_id, data_loader_re_id, feature_map_dims)\n",
    "result_re_id_flipped = cnn.Inference(model_re_id, data_loader_re_id_flipped, feature_map_dims)\n",
    "features = result_re_id + result_re_id_flipped ;\n",
    "temp = torch.norm(features, p=2, dim=1, keepdim=True)\n",
    "unit_features = features.div(temp.expand_as(features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dataset_to_re_id, data_loader_re_id, dataset_to_re_id_flipped, data_loader_re_id_flipped\n",
    "torch.cuda.empty_cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "treshold = 0.6;\n",
    "feature_list = torch.unsqueeze(unit_features[0, :], 0).to(device)\n",
    "ids_list = torch.tensor([1], dtype=torch.int)\n",
    "for i in range(1,unit_features.size()[0]):\n",
    "    query = torch.unsqueeze(unit_features[i, :], 0).to(device);\n",
    "    query_raveled = query.view(-1,1);\n",
    "    score = torch.mm(feature_list, query_raveled);\n",
    "    max_val, max_ind = torch.max(score, 0);\n",
    "    # spike is already in list\n",
    "    if(max_val.item() > treshold):\n",
    "        ids_list = torch.cat((ids_list, torch.tensor([ids_list[max_ind.item()]], dtype = torch.int)), 0);\n",
    "    # adds a new spike id\n",
    "    else:\n",
    "        new_id = torch.max(ids_list, 0)[0] + 1;\n",
    "        ids_list = torch.cat((ids_list, torch.tensor([new_id.item()], dtype = torch.int)), 0);\n",
    "\n",
    "    feature_list = torch.cat((feature_list, query), 0);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  6,  8,  9, 10,  6,  3, 10,  2,  3,  1,  4,\n",
       "         3,  4,  3, 11, 12,  4,  8, 13, 14,  3,  8, 10,  3, 15, 16, 17, 10,  3,\n",
       "         3, 10,  6,  4, 18, 13,  3, 19, 15,  9, 13, 18, 20, 15,  3, 11, 13,  6,\n",
       "         8,  3, 21,  3, 10,  9, 16, 15,  8, 19, 10, 20,  3,  3, 15, 11,  1, 15,\n",
       "        10, 22,  3,  3, 23, 11,  3,  3, 18, 17, 21,  8, 18,  3, 16, 13, 16,  3,\n",
       "        10, 15,  3, 13, 24, 15,  3,  4,  3, 22], dtype=torch.int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_list[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp =np.load(path_to_ground_truth_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33]\n",
      "[ 687    5 3477  980  107 1087    2  929  634 1039  487    2  465   10\n",
      "  994  172  210  888   41  554  731  645    4    6    1  220    7    1\n",
      "  195  568    2    3    1]\n"
     ]
    }
   ],
   "source": [
    "unique_classes, nb_of_occourences = np.unique(ids_list, return_counts=True);\n",
    "print(unique_classes)\n",
    "print(nb_of_occourences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33]\n",
      "[ 687    5 3477  980  107 1087    2  929  634 1039  487    2  465   10\n",
      "  994  172  210  888   41  554  731  645    4    6    1  220    7    1\n",
      "  195  568    2    3    1]\n"
     ]
    }
   ],
   "source": [
    "unique_classes_gt, nb_of_occourences_gt = np.unique(temp[1, :], return_counts=True);\n",
    "print(unique_classes)\n",
    "print(nb_of_occourences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_spike_index = [];\n",
    "found = [];\n",
    "for i in range(max_amplitude_index.size()[1]):\n",
    "    spike = max_amplitude_index[0, i];\n",
    "    ind =np.where(spike.numpy() == temp[0, :].astype(int))\n",
    "    if(len(ind[0]) == 0):\n",
    "        found.append(0);\n",
    "        found_spike_index.append(0)\n",
    "\n",
    "    else:\n",
    "        found.append(1)\n",
    "        found_spike_index.append(int(temp[1, ind[0]]) + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "found = np.asarray(found)\n",
    "found_spike_index = np.asarray(found_spike_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9196911706480138\n",
      "1217\n"
     ]
    }
   ],
   "source": [
    "tp = np.where(found == 1)[0].size\n",
    "fp = ntotalp.where(found == 0)[0].size\n",
    "print(tp / (tp+fp))\n",
    "print(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_classes, nb_of_occourences = np.unique(found_spike_index, return_counts=True);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_classes.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_classes, nb_of_occourences = np.unique(found_spike_index, return_counts=True);\n",
    "\n",
    "spike_classes = np.empty((unique_classes.size,),dtype=object)\n",
    "for i in range(spike_classes.size):\n",
    "    spike_classes[i] = [];\n",
    "for i in range(found_spike_index.size):\n",
    "    index = found_spike_index[i];\n",
    "    index_re_id = ids_list[i]\n",
    "    if (index == 0):\n",
    "        spike_classes[index].append(index_re_id.item());\n",
    "    else:\n",
    "        spike_classes[index].append(index_re_id.item())\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max occ:  2489 total:  2497\n",
      "max occ:  209 total:  262\n",
      "max occ:  483 total:  483\n",
      "max occ:  168 total:  168\n",
      "max occ:  194 total:  194\n",
      "max occ:  683 total:  687\n",
      "max occ:  630 total:  630\n",
      "max occ:  957 total:  957\n",
      "max occ:  629 total:  672\n",
      "max occ:  213 total:  219\n",
      "max occ:  992 total:  993\n",
      "max occ:  842 total:  844\n",
      "max occ:  872 total:  879\n",
      "max occ:  554 total:  594\n",
      "max occ:  969 total:  970\n",
      "max occ:  731 total:  838\n",
      "max occ:  550 total:  553\n",
      "max occ:  463 total:  476\n",
      "max occ:  1019 total:  1021\n"
     ]
    }
   ],
   "source": [
    "tp = 0;\n",
    "total = 0;\n",
    "for i in range(1, spike_classes.size):\n",
    "    unique_classes, nb_of_occourences = np.unique(spike_classes[i], return_counts=True);\n",
    "    tp = tp + np.max(nb_of_occourences);\n",
    "    total = total + np.sum(nb_of_occourences);\n",
    "    print(\"max occ: \", np.max(nb_of_occourences), \"total: \", np.sum(nb_of_occourences))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9791920786395925"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3 957   8 130   3   4  20   4   1   1   4  46   1   4  10   7   1  13]\n"
     ]
    }
   ],
   "source": [
    "unique_classes, nb_of_occourences = np.unique(spike_classes[0], return_counts=True);\n",
    "print(nb_of_occourences)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

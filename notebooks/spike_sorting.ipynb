{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from os.path import expanduser\n",
    "from os import path\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder = os.path.dirname(os.getcwd())\n",
    "path_to_ground_truth_data = path.join(root_folder,'data/synthesized/gt_46.npy');\n",
    "path_to_recording= path.join(root_folder,'data/synthesized/data_46.npy');\n",
    "\n",
    "sys.path.append(root_folder)\n",
    "from custom_resnet import CustomResnet as cnn\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "waveform_length = 72;\n",
    "step_size = int(np.round(waveform_length * 0.1))\n",
    "batch_size = 15000;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads spike detection model\n",
    "num_classes_detect = 2;\n",
    "path_to_model_detect = path.join(root_folder, 'models/detect/resnet18_num_classes_2_epoch_19.pt')\n",
    "model_detect = cnn.resnet18(num_classes=num_classes_detect);\n",
    "checkpoint = torch.load(path_to_model_detect)\n",
    "model_detect.load_state_dict(checkpoint['model_state_dict'])\n",
    "model_detect.to(device);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads re id model\n",
    "num_classes_re_id = 499;\n",
    "path_to_model_re_id = path.join(root_folder, 'models/re_id/resnet18_num_classes_499_epoch_74.pt')\n",
    "model_re_id = cnn.ft_net(class_num = num_classes_re_id);\n",
    "checkpoint = torch.load(path_to_model_re_id)\n",
    "model_re_id.load_state_dict(checkpoint['model_state_dict'])\n",
    "model_re_id.to(device);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.98707844 -0.98707844] [ 1.         -0.97415687]\n"
     ]
    }
   ],
   "source": [
    "# transforms data for inference\n",
    "transform = transforms.Compose([cnn.FilterSignalUsingButtersWorth('high', 24000, np.array([100], dtype=int), 1), cnn.OptimizedZScoreNormalizaton()])\n",
    "recording = cnn.Recording(path_to_recording, transform = transform);\n",
    "recording = cnn.AddPaddingToRecording(recording, step_size, waveform_length)\n",
    "# gets waveform data for each window\n",
    "waveform_indices = cnn.GetWaveformIndices(recording, step_size, waveform_length)\n",
    "transform = transforms.Compose([cnn.ExtractWaveforms(waveform_indices, waveform_length)])\n",
    "waveforms = transform(recording.data);\n",
    "normalized_waveforms = waveforms;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.FloatTensor\n",
      "done:  0  batch\n",
      "done:  1  batch\n",
      "done:  2  batch\n",
      "done:  3  batch\n",
      "done:  4  batch\n",
      "done:  5  batch\n",
      "done:  6  batch\n",
      "done:  7  batch\n",
      "done:  8  batch\n",
      "done:  9  batch\n",
      "done:  10  batch\n",
      "done:  11  batch\n",
      "done:  12  batch\n",
      "done:  13  batch\n",
      "done:  14  batch\n",
      "done:  15  batch\n",
      "done:  16  batch\n",
      "done:  17  batch\n",
      "done:  18  batch\n",
      "done:  19  batch\n",
      "done:  20  batch\n",
      "done:  21  batch\n",
      "done:  22  batch\n",
      "done:  23  batch\n",
      "done:  24  batch\n",
      "done:  25  batch\n",
      "done:  26  batch\n",
      "done:  27  batch\n",
      "done:  28  batch\n",
      "done:  29  batch\n",
      "done:  30  batch\n",
      "done:  31  batch\n",
      "done:  32  batch\n",
      "done:  33  batch\n",
      "done:  34  batch\n",
      "done:  35  batch\n",
      "done:  36  batch\n",
      "done:  37  batch\n",
      "done:  38  batch\n",
      "done:  39  batch\n",
      "done:  40  batch\n",
      "done:  41  batch\n",
      "done:  42  batch\n",
      "done:  43  batch\n",
      "done:  44  batch\n",
      "done:  45  batch\n",
      "done:  46  batch\n",
      "done:  47  batch\n",
      "done:  48  batch\n",
      "done:  49  batch\n",
      "done:  50  batch\n",
      "done:  51  batch\n",
      "done:  52  batch\n",
      "done:  53  batch\n",
      "done:  54  batch\n",
      "done:  55  batch\n",
      "done:  56  batch\n",
      "done:  57  batch\n",
      "done:  58  batch\n",
      "done:  59  batch\n",
      "done:  60  batch\n",
      "done:  61  batch\n",
      "done:  62  batch\n",
      "done:  63  batch\n",
      "done:  64  batch\n",
      "done:  65  batch\n",
      "done:  66  batch\n",
      "done:  67  batch\n",
      "done:  68  batch\n",
      "done:  69  batch\n",
      "done:  70  batch\n",
      "done:  71  batch\n",
      "done:  72  batch\n",
      "done:  73  batch\n",
      "done:  74  batch\n",
      "done:  75  batch\n",
      "done:  76  batch\n",
      "done:  77  batch\n",
      "done:  78  batch\n",
      "done:  79  batch\n",
      "done:  80  batch\n",
      "done:  81  batch\n",
      "done:  82  batch\n",
      "done:  83  batch\n",
      "done:  84  batch\n",
      "done:  85  batch\n",
      "done:  86  batch\n",
      "done:  87  batch\n",
      "done:  88  batch\n",
      "done:  89  batch\n",
      "done:  90  batch\n",
      "done:  91  batch\n",
      "done:  92  batch\n",
      "done:  93  batch\n",
      "done:  94  batch\n",
      "done:  95  batch\n",
      "done:  96  batch\n",
      "done:  97  batch\n",
      "done:  98  batch\n",
      "done:  99  batch\n",
      "done:  100  batch\n",
      "done:  101  batch\n",
      "done:  102  batch\n",
      "done:  103  batch\n",
      "done:  104  batch\n",
      "done:  105  batch\n",
      "done:  106  batch\n",
      "done:  107  batch\n",
      "done:  108  batch\n",
      "done:  109  batch\n",
      "done:  110  batch\n",
      "done:  111  batch\n",
      "done:  112  batch\n",
      "done:  113  batch\n",
      "done:  114  batch\n",
      "done:  115  batch\n",
      "done:  116  batch\n",
      "done:  117  batch\n",
      "done:  118  batch\n",
      "done:  119  batch\n",
      "done:  120  batch\n",
      "done:  121  batch\n",
      "done:  122  batch\n",
      "done:  123  batch\n",
      "done:  124  batch\n",
      "done:  125  batch\n",
      "done:  126  batch\n",
      "done:  127  batch\n",
      "done:  128  batch\n",
      "done:  129  batch\n",
      "done:  130  batch\n",
      "done:  131  batch\n",
      "done:  132  batch\n",
      "done:  133  batch\n",
      "done:  134  batch\n",
      "done:  135  batch\n",
      "done:  136  batch\n",
      "done:  137  batch\n"
     ]
    }
   ],
   "source": [
    "### spike detection pipeline\n",
    "# loads data for inference\n",
    "dataset_to_infer_detect = cnn.InferenceDataset(normalized_waveforms.to(device));\n",
    "data_loader_detect = torch.utils.data.DataLoader(dataset_to_infer_detect, batch_size=batch_size, shuffle=False, num_workers=0);\n",
    "\n",
    "#inference for detection \n",
    "result_detect = cnn.Inference(model_detect, data_loader_detect, num_classes_detect)\n",
    "treshold = 0.9;\n",
    "predictions = cnn.PredictionByTreshold(result_detect, treshold)\n",
    "max_amplitude_index = cnn.GetNonOverlappingSpikesMaxAmplitude(recording, predictions, waveform_length, waveforms, waveform_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dataset_to_infer_detect, data_loader_detect\n",
    "torch.cuda.empty_cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_out_of_bound_index = np.where((max_amplitude_index >= 0) & (max_amplitude_index < recording.__len__()));\n",
    "max_amplitude_index = max_amplitude_index[non_out_of_bound_index];\n",
    "\n",
    "max_amplitude_index = torch.unsqueeze(torch.tensor(max_amplitude_index), 0);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5566])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_amplitude_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.FloatTensor\n",
      "torch.cuda.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "# spike classficiation pipeline\n",
    "transform = transforms.Compose([cnn.ExtractWaveforms(max_amplitude_index, waveform_length)])\n",
    "waveforms_re_id = transform(recording.data);\n",
    "#vertical flip\n",
    "waveforms_re_id_flipped = waveforms_re_id * -1;\n",
    "# data loading for inference\n",
    "dataset_to_re_id = cnn.InferenceDataset(waveforms_re_id.to(device));\n",
    "data_loader_re_id = torch.utils.data.DataLoader(dataset_to_re_id, batch_size=batch_size, shuffle=False, num_workers=0);\n",
    "dataset_to_re_id_flipped = cnn.InferenceDataset(waveforms_re_id_flipped.to(device));\n",
    "data_loader_re_id_flipped = torch.utils.data.DataLoader(dataset_to_re_id_flipped, batch_size=batch_size, shuffle=False, num_workers=0);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done:  0  batch\n",
      "done:  0  batch\n"
     ]
    }
   ],
   "source": [
    "# exracts features\n",
    "feature_map_dims = 128\n",
    "features = torch.FloatTensor(0 , 128).zero_();\n",
    "model_re_id.model.fc.classifier = nn.Sequential()\n",
    "result_re_id = cnn.Inference(model_re_id, data_loader_re_id, feature_map_dims)\n",
    "result_re_id_flipped = cnn.Inference(model_re_id, data_loader_re_id_flipped, feature_map_dims)\n",
    "features = result_re_id + result_re_id_flipped ;\n",
    "temp = torch.norm(features, p=2, dim=1, keepdim=True)\n",
    "unit_features = features.div(temp.expand_as(features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dataset_to_re_id, data_loader_re_id, dataset_to_re_id_flipped, data_loader_re_id_flipped\n",
    "torch.cuda.empty_cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "treshold = 0.6;\n",
    "feature_list = torch.unsqueeze(unit_features[0, :], 0).to(device)\n",
    "ids_list = torch.tensor([1], dtype=torch.int)\n",
    "for i in range(1,unit_features.size()[0]):\n",
    "    query = torch.unsqueeze(unit_features[i, :], 0).to(device);\n",
    "    query_raveled = query.view(-1,1);\n",
    "    score = torch.mm(feature_list, query_raveled);\n",
    "    max_val, max_ind = torch.max(score, 0);\n",
    "    # spike is already in list\n",
    "    if(max_val.item() > treshold):\n",
    "        ids_list = torch.cat((ids_list, torch.tensor([ids_list[max_ind.item()]], dtype = torch.int)), 0);\n",
    "    # adds a new spike id\n",
    "    else:\n",
    "        new_id = torch.max(ids_list, 0)[0] + 1;\n",
    "        ids_list = torch.cat((ids_list, torch.tensor([new_id.item()], dtype = torch.int)), 0);\n",
    "\n",
    "    feature_list = torch.cat((feature_list, query), 0);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 2, 3, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1,\n",
       "        1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 2,\n",
       "        1, 1, 1, 2, 1, 1, 1, 1, 1, 3, 2, 1, 1, 1, 1, 1, 2, 1, 4, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 4, 4, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 3, 1, 1,\n",
       "        1, 1, 1, 1], dtype=torch.int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_list[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp =np.load(path_to_ground_truth_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5]\n",
      "[4231  919  171  244    1]\n"
     ]
    }
   ],
   "source": [
    "unique_classes, nb_of_occourences = np.unique(ids_list, return_counts=True);\n",
    "print(unique_classes)\n",
    "print(nb_of_occourences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 2.]\n",
      "[2865  416  919]\n"
     ]
    }
   ],
   "source": [
    "unique_classes_gt, nb_of_occourences_gt = np.unique(temp[1, :], return_counts=True);\n",
    "print(unique_classes_gt)\n",
    "print(nb_of_occourences_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5]\n",
      "[4231  919  171  244    1]\n"
     ]
    }
   ],
   "source": [
    "unique_classes_gt, nb_of_occourences_gt = np.unique(ids_list, return_counts=True);\n",
    "print(unique_classes_gt)\n",
    "print(nb_of_occourences_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_spike_index = [];\n",
    "found = [];\n",
    "for i in range(max_amplitude_index.size()[1]):\n",
    "    spike = max_amplitude_index[0, i];\n",
    "    ind =np.where(spike.numpy() == temp[0, :].astype(int))\n",
    "    if(len(ind[0]) == 0):\n",
    "        found.append(0);\n",
    "        found_spike_index.append(0)\n",
    "\n",
    "    else:\n",
    "        found.append(1)\n",
    "        found_spike_index.append(int(temp[1, ind[0]]) + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "found = np.asarray(found)\n",
    "found_spike_index = np.asarray(found_spike_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9523809523809523\n",
      "1566\n"
     ]
    }
   ],
   "source": [
    "tp = np.where(found == 1)[0].size\n",
    "fp = np.where(found == 0)[0].size\n",
    "print(tp / temp[1, :].size)\n",
    "print(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5566"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "found.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3]\n",
      "[1566 2668  415  917]\n"
     ]
    }
   ],
   "source": [
    "unique_classes, nb_of_occourences = np.unique(found_spike_index, return_counts=True);\n",
    "print(unique_classes)\n",
    "print(nb_of_occourences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2. 3.]\n",
      "[2865  416  919]\n"
     ]
    }
   ],
   "source": [
    "unique_classes_gt, nb_of_occourences_gt = np.unique(temp[1, :], return_counts=True);\n",
    "print(unique_classes_gt + 1)\n",
    "print(nb_of_occourences_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_classes, nb_of_occourences = np.unique(found_spike_index, return_counts=True);\n",
    "\n",
    "spike_classes = np.empty((unique_classes.size,),dtype=object)\n",
    "for i in range(spike_classes.size):\n",
    "    spike_classes[i] = [];\n",
    "for i in range(found_spike_index.size):\n",
    "    index = found_spike_index[i];\n",
    "    index_re_id = ids_list[i]\n",
    "    if (index == 0):\n",
    "        spike_classes[index].append(index_re_id.item());\n",
    "    else:\n",
    "        spike_classes[index].append(index_re_id.item())\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max occ:  2668 total:  2668 id:  1\n",
      "max occ:  243 total:  415 id:  4\n",
      "max occ:  917 total:  917 id:  2\n"
     ]
    }
   ],
   "source": [
    "tp = 0;\n",
    "total = 0;\n",
    "for i in range(1, spike_classes.size):\n",
    "    unique_classes, nb_of_occourences = np.unique(spike_classes[i], return_counts=True);\n",
    "    tp = tp + np.max(nb_of_occourences);\n",
    "    total = total + np.sum(nb_of_occourences);\n",
    "    print(\"max occ: \", np.max(nb_of_occourences), \"total: \", np.sum(nb_of_occourences), \"id: \", unique_classes[np.argmax(nb_of_occourences)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.957"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1563    2    1]\n"
     ]
    }
   ],
   "source": [
    "unique_classes, nb_of_occourences = np.unique(spike_classes[0], return_counts=True);\n",
    "print(nb_of_occourences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
